---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-server
spec:
  selector:
    matchLabels:
      app: model-server
  template:
    metadata:
      labels:
        app: model-server
    spec:
      initContainers:
      - name: init-model
        image: alpine
        command: ["sh", "-c"]
        args:
        - |
          while [ ! -f /models/${MODEL_NAME}/${MODEL_VERSION}/model.pt ]; do
            echo "Waiting for the model to be ready..."
            sleep 1
          done && \
          echo "Model is ready."
        envFrom:
        - configMapRef:
            name: model-server
        volumeMounts:
        - name: models
          mountPath: /models
          readOnly: true
        securityContext:
          allowPrivilegeEscalation: false
      containers:
      - name: triton-server
        image: nvcr.io/nvidia/tritonserver:25.01-py3
        command: ["sh", "-c"]
        args:
        - |
          tritonserver \
            --model-repository=${MODEL_REPOSITORY}
        envFrom:
        - configMapRef:
            name: model-server
        resources:
          requests:
            memory: 100Mi
          limits:
            memory: 1Gi
            cpu: 1000m
        ports:
        - name: http
          containerPort: 8000
          protocol: TCP
        - name: grpc
          containerPort: 8001
          protocol: TCP
        volumeMounts:
        - name: models
          mountPath: /models
          readOnly: true
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: models
---
apiVersion: v1
kind: Service
metadata:
  name: model-server
spec:
  selector:
    app: model-server
  ports:
  - name: http
    port: 8000
    targetPort: http
  - name: grpc
    port: 8001
    targetPort: grpc
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: model-server
data:
  MODEL_REPOSITORY: "/models"
  MODEL_NAME: "pilot"
  MODEL_VERSION: "1"
